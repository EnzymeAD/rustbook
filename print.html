<!DOCTYPE HTML>
<html lang="en" class="light sidebar-visible" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title></title>
        <meta name="robots" content="noindex">


        <!-- Custom HTML head -->

        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" id="highlight-css" href="highlight.css">
        <link rel="stylesheet" id="tomorrow-night-css" href="tomorrow-night.css">
        <link rel="stylesheet" id="ayu-highlight-css" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->

        <!-- MathJax -->
        <script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

        <!-- Provide site root and default themes to javascript -->
        <script>
            const path_to_root = "";
            const default_light_theme = "light";
            const default_dark_theme = "navy";
        </script>
        <!-- Start loading toc.js asap -->
        <script src="toc.js"></script>
    </head>
    <body>
    <div id="body-container">
        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                let theme = localStorage.getItem('mdbook-theme');
                let sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            const default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? default_dark_theme : default_light_theme;
            let theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            const html = document.documentElement;
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add("js");
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            let sidebar = null;
            const sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
            }
            sidebar_toggle.checked = sidebar === 'visible';
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <!-- populated by js -->
            <mdbook-sidebar-scrollbox class="sidebar-scrollbox"></mdbook-sidebar-scrollbox>
            <noscript>
                <iframe class="sidebar-iframe-outer" src="toc.html"></iframe>
            </noscript>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="default_theme">Auto</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title"></h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="why-autodiff"><a class="header" href="#why-autodiff">Why Autodiff?</a></h1>
<p>We propose to add <a href="https://en.wikipedia.org/wiki/Automatic_differentiation">automatic differentiation</a> to Rust.  This would allow Rust users to compute derivatives of arbitrary functions, which is the essential enabling technology for <a href="https://en.wikipedia.org/wiki/Differentiable_programming">differentiable programming</a>. This feature would open new opportunities for Rust in scientific computing, machine learning, robotics, computer vision, probabilistic analysis, and other fields.</p>
<h2 id="case-studies-from-autodiff-developersusers"><a class="header" href="#case-studies-from-autodiff-developersusers">Case studies from autodiff developers/users</a></h2>
<h3 id="jan-hückelheim-argonne-national-lab-us"><a class="header" href="#jan-hückelheim-argonne-national-lab-us">Jan Hückelheim (Argonne National Lab, US):</a></h3>
<blockquote>
<p>Automatic differentiation (AD, also known as autodiff or back-propagation) has been used at Argonne and other national laboratories, at least, since the 1980s. For example, we have used AD to obtain gradients of computational fluid dynamics applications for shape-optimization, which allows the automated design of aircraft wings or turbine blades to minimize drag or fuel consumption. AD is used extensively in many other applications including seismic imaging, climate modeling, quantum computing, or software verification.</p>
<p>Besides the aforementioned “conventional” uses of AD, it is also a cornerstone for the development of ML methods that incorporate physical models. The 2022 department of energy report on Advanced Research Directions on AI for Science, Energy, and Security states that “End-to-end differentiability for composing simulation and inference in a virtuous loop is required to integrate first-principles calculations and advanced AI training and inference”. It is therefore conceivable that AD usage and development will become even more important in the near future.
<a href="https://www.anl.gov/sites/www/files/2023-05/AI4SESReport-2023.pdf">1</a></p>
</blockquote>
<h3 id="prof-jed-brown-cu-boulder-us"><a class="header" href="#prof-jed-brown-cu-boulder-us">Prof. Jed Brown (CU Boulder, US):</a></h3>
<blockquote>
<p>My primary applications are in computational mechanics (constitutive modeling and calibration), where it'll enable us to give a far better user experience than commercial packages, but differentiable programming is a key enabler for a lot of scientific computing and ML research and production.</p>
</blockquote>
<h1 id="background"><a class="header" href="#background">Background</a></h1>
<h2 id="what-is-autodiff-used-for"><a class="header" href="#what-is-autodiff-used-for">What is autodiff used for?</a></h2>
<p>Autodiff is widely used to evaluate gradients for numerical optimization, which is otherwise intractable for a large number of parameters.
Indeed, suppose we have a scalar-valued loss function \(f(\theta)\) where the parameter vector \(\theta\) has length \(n\).
If the cost to evaluate \(f(x)\) once is \(c\) (which will often be \(O(n)\)), then evaluating the gradient \(\partial f/\partial x\)
costs less than \(3n\) with autodiff or tedious and brittle by-hand implementation, but \(cn\) otherwise.
Optimization of systems of size \(n\) in the hundreds to billions are common in applications such as calibration, data assimilation, and design optimization of physical models, in perception and control systems for robotics, and machine learning.</p>
<p>Derivatives are also instrumental to thermodynamically admissible physical models, in which models are developed using non-observable free energy functionals and dissipation potentials, with observable dynamics represented by their derivatives. Commercial engineering software requires users to implement these derivatives by hand (e.g., Abaqus <a href="https://abaqus-docs.mit.edu/2017/English/SIMACAESUBRefMap/simasub-c-uhyper.htm#simasub-c-uhyper-t-vartodefine1"><code>UHYPER</code></a> and <a href="https://abaqus-docs.mit.edu/2017/English/SIMACAESUBRefMap/simasub-c-umat.htm#simasub-c-umat-t-vartodefine1"><code>UMAT</code></a>) and constitutive modeling papers routinely spend many pages detailing how to efficiently compute the necessary derivatives since these are among the most computationally intensive parts of simulation-based workflows and numerical stability is necessary.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="prior-art"><a class="header" href="#prior-art">Prior art</a></h1>
<p>Autodiff emerged as an identified mathematical framework and software tool in the 1980s, building on groundwork from previous decades. The common implementation strategies were operator overloading and source transformation. In the former approach, one replaces scalars with a pair carrying the primary and variation and overloads elementary operations, leading to code similar to the following:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>struct ActiveReal(f64, f64);

impl Add for ActiveReal {
    type Output = Self;
    fn add(self, rhs: Self) -&gt; Self::Output {
        Self(self.0 + rhs.0, self.1 + rhs.1)
    }
}

impl Mul for ActiveReal {
    type Output = Self;
    fn mul(self, rhs: Self) -&gt; Self {
        // Evoke the product rule, d(xy) = x * dy + dx * y
        Self(self.0 * rhs.0, self.0 * rhs.1 + self.1 * rhs.0)
    }
}
<span class="boring">}</span></code></pre></pre>
<p>This approach can be distributed in a library (in languages that support operator overloading), but in practice, it means making most user functions generic and has serious performance impacts. For example, loops are effectively unrolled and this strategy is harmful to vectorization since "even and odd lanes" require different processing. Some libraries, especially in C++, have applied heavy template metaprogramming to make those libraries reasonably performant, but they still lag behind and have obtuse error messages.</p>
<p>The second approach, source transformation, was first applied to Fortran and later C, but never differentiated the complete language. Those systems implemented their own parsers and would generate new source files with mangled symbols and calling conventions, to be manually included by the build systems. Such approaches could be much more efficient by retaining loop structure and enabling vectorization, but the language coverage was always incomplete and they have historically been difficult to install (e.g., OpenAD depended on the research compiler ROSE, which could only be compiled with a specific version of gcc). Error handling and debugging is also poor with this approach.</p>
<p>Autodiff remained an active research area with relatively clumsy research-grade tooling for decades. Select scientific applications, such as MITgcm, would shape their entire software engineering around enabling source transformation tools to compute derivatives. The most recent machine learning boom was precipitated by autodiff engineering improving to the point where practitioners could rapidly design new neural network architectures and have efficient gradients automatically available for gradient-based optimization. The modern deep learning libraries (PyTorch, TensorFlow, JAX) have grown into more general autodiff tools, albeit with language restrictions and <a href="https://jax.readthedocs.io/en/latest/notebooks/Common_Gotchas_in_JAX.html#control-flow">sharp edges</a> due to custom JIT compilation separate from their host language (Python with C++ infrastructure).</p>
<p>Enzyme takes advantage of the fact that while differentiating all features of the source language is a monumental task, differentiating a single-statement assignment (SSA) form such as LLVM IR is far more tractable and allows complete language coverage. Since it's based on LLVM, it is language-agnostic for all LLVM-based languages.</p>
<p>TODO: https://enzyme.mit.edu/conference/assets/JanHueckelheim_EnzymeCon2023.pdf [<a href="https://arxiv.org/abs/2305.07546">paper</a>]</p>
<p>TODO: Talk about Torch, TensorFlow, PyTorch, JAX, Julia, etc.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="installation"><a class="header" href="#installation">Installation</a></h1>
<p>Build instructions are available in the <a href="https://rustc-dev-guide.rust-lang.org/autodiff/installation.html">rustc-dev-guide</a>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="usage"><a class="header" href="#usage">Usage</a></h1>
<p>Enzyme differentiates arbitrary multivariate vector functions as the most general case in automatic differentiation</p>
<p>\[
f: \mathbb{R}^n \rightarrow \mathbb{R}^m, y = f(x)
\]</p>
<p>For simplicity we define a vector function with \(m=1\).
However, this tutorial can easily be applied to arbitrary \(m \in \mathbb{N}\).</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn f(x: &amp;[f32], y: &amp;mut f32) {
    *y = x[0] * x[0] + x[1] * x[0];
}
<span class="boring">}</span></code></pre></pre>
<p>We also support functions that return a float value:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn g(x: &amp;[f32]) -&gt; f32 {
    x[0] * x[0] + x[1] * x[0]
}
<span class="boring">}</span></code></pre></pre>
<h2 id="forward-mode"><a class="header" href="#forward-mode">Forward Mode</a></h2>
<p>The forward model is defined as
\[
\begin{aligned}
y &amp;= f(x) \\
\dot{y} &amp;= \nabla f(x) \cdot \dot{x}
\end{aligned}
\]</p>
<p>To obtain the first element of the gradient using the forward model
we have to seed \(\dot{x}\) with \(\dot{x}=[1.0,0.0]\).</p>
<p>In the forward mode the second element which gets added for Dual arguments stores the tangent.</p>
<pre><pre class="playground"><code class="language-rust">    use std::autodiff::autodiff;
    #[autodiff(df, Forward, Dual, Dual)]
    fn f(x: &amp;[f32; 2], y: &amp;mut f32) {
        *y = x[0] * x[0] + x[1] * x[0];
    }

    fn main() {
        let x = [2.0, 3.0];
        let dx = [1.0, 0.0];
        let mut y = 0.0;
        let mut dy = 0.0;
        df(&amp;x, &amp;dx, &amp;mut y, &amp;mut dy);
        assert_eq!(10.0, y);
        assert_eq!(7.0, dy);
    }</code></pre></pre>
<p>In the returning case we would write similar code, note that in this case
the second Dual refers to our return value.</p>
<pre><pre class="playground"><code class="language-rust">    use std::autodiff::autodiff;
    #[autodiff(df, Forward, Dual, Dual)]
    fn f(x: &amp;[f32; 2]) -&gt; f32 { x[0] * x[0] + x[1] * x[0] }

    fn main() {
        let x  = [2.0, 2.0];
        let dx = [1.0, 0.0];
        let (y, dy) = df(&amp;x, &amp;dx);
        assert_eq!(dy, 2.0 * x[0] + x[1]);
        assert_eq!(y, f(&amp;x));
    }</code></pre></pre>
<p>Note that to acquire the full gradient one needs to execute the forward model a second time with the seed <code>dx</code> set to <code>[0.0, 1.0]</code>.</p>
<h2 id="reverse-mode"><a class="header" href="#reverse-mode">Reverse Mode</a></h2>
<p>The reverse model in AD is defined as
\[
\begin{aligned}
y &amp;= f(x) \\
\bar{x} &amp;= \bar{y} \cdot \nabla f(x)
\end{aligned}
\]
where the bar denotes an adjoint variable. Note that executing AD in reverse mode takes \(x, \bar y\) as input and computes \(y, \bar x\) as output.</p>
<p>Enzyme stores the value and adjoint of a variable when marking a type
as <code>Duplicated</code>. Then the first element represent the value and the second
the adjoint. Evaluating the reverse model using Enzyme is done in the
following example.</p>
<pre><pre class="playground"><code class="language-rust">    use std::autodiff::autodiff;
    #[autodiff(df, Reverse, Duplicated, Duplicated)]
    fn f(x: &amp;[f32; 2], y: &amp;mut f32) {
        *y = x[0] * x[0] + x[1] * x[0];
    }

    fn main() {
        let x = [2.0, 3.0];
        let mut bx = [0.0, 0.0];
        let mut y = 0.0;
        let mut by = 1.0; // seed
        df(&amp;x, &amp;mut bx, &amp;mut y, &amp;mut by);
        assert_eq!([7.0, 2.0], bx);
        assert_eq!(10.0, y);
        assert_eq!(0.0, by); // seed is zeroed
    }</code></pre></pre>
<p>This yields the gradient of <code>f</code> in <code>bx</code> at point <code>x = [2.0, 2.0]</code>.
<code>by</code> is called the seed and has to be set to <code>1.0</code> in order to compute
the gradient. Please note that unlike <code>Dual</code>, for <code>Duplicated</code> the seed
is getting zeroed, which is required for correctness in certain cases.
Note that the output <code>bx</code> is initialized to zero on input, and <code>df</code> <em>accumulates</em> into it.</p>
<p>We can again also handle functions returning a scalar. In this case we mark the
return value as duplicated. The seed is then going to be an extra,
last input argument.</p>
<pre><pre class="playground"><code class="language-rust">    use std::autodiff::autodiff;
    #[autodiff(df, Reverse, Duplicated, Active)]
    fn f(x: &amp;[f32; 2]) -&gt; f32 {
        x[0] * x[0] + x[1] * x[0]
    }

    fn main() {
        let x = [2.0, 3.0];
        let mut bx = [0.0, 0.0];
        let by = 1.0; // seed
        let y = df(&amp;x, &amp;mut bx, by);
        assert_eq!([7.0, 2.0], bx);
        assert_eq!(10.0, y);
    }</code></pre></pre>
<p>We can now verify that indeed the reverse mode and forward mode yield the same result.</p>
<pre><pre class="playground"><code class="language-rust">    use std::autodiff::autodiff;
    #[autodiff(df_fwd, Forward, Dual, Dual)]
    #[autodiff(df_rev, Reverse, Duplicated, Duplicated)]
    fn f(x: &amp;[f32; 2], y: &amp;mut f32) {
        *y = x[0] * x[0] + x[1] * x[0];
    }

    fn main() {
        let x = [2.0, 3.0];

        // Compute gradient via forward-mode
        let dx_0 = [1.0, 0.0];
        let dx_1 = [0.0, 1.0];
        let mut y = 0.0;
        let mut dy_f = [0.0, 0.0];
        df_fwd(&amp;x, &amp;dx_0, &amp;mut y, &amp;mut dy_f[0]);
        df_fwd(&amp;x, &amp;dx_1, &amp;mut y, &amp;mut dy_f[1]);
        assert_eq!([7.0, 2.0], dy_f);

        // Compute gradient via reverse-mode
        let mut bx = [0.0, 0.0];
        let mut y = 0.0;
        let mut by = 1.0; // seed
        df_rev(&amp;x, &amp;mut bx, &amp;mut y, &amp;mut by);
        assert_eq!([7.0, 2.0], bx);
        assert_eq!(10.0, y);
        assert_eq!(0.0, by); // seed is zeroed
    }</code></pre></pre>
<p>As we can see, the number of calls under Forward mode scales with the number of
input values. Reverse mode scales with the number of output parameters,
and is therefore preferable if we have less outputs than inputs. A common example
is the training of neural networks, where we have a single output (loss),
but a large input (weights).</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="forward-mode-1"><a class="header" href="#forward-mode-1">Forward Mode</a></h1>
<p>Forward mode (often also called Dual mode) is generally recommended if the output dimension is greater than the active input dimension, or if the dimension is similar. Dimension here refers to the total number of scalar values in all input (output, respectively) arguments.</p>
<p>We annotate input and output arguments either with <code>Const</code>, <code>Dual</code>, or <code>DualOnly</code>.</p>
<p>In Forward mode we are only allowed to mark input arguments with <code>Dual</code> or <code>Const</code>.
The return value of forward mode with a <code>Dual</code> return is a tuple containing as the first value the primal return value and as the second value the derivative.</p>
<p>In forward mode <code>Dual</code> with two arguments <code>x, 0.0</code> is equivalent to <code>Const</code> passing only <code>x</code>, except that we can perform more optimizations for <code>Const</code>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="reverse-mode-1"><a class="header" href="#reverse-mode-1">Reverse Mode</a></h1>
<h1 id="autodiff-on-llvm-ir"><a class="header" href="#autodiff-on-llvm-ir">Autodiff on LLVM IR</a></h1>
<p>TODO: Typical LICM \(O(n)\) vs \(O(n^2)\) Enzyme example.
TODO: Talk about what makes this approach special and a good fit for Rust conceptually.</p>
<h2 id="changes-to-rust"><a class="header" href="#changes-to-rust">Changes to Rust</a></h2>
<p>TODO: Talk about the new attributes and define the semantics of these new attributes. Give examples.</p>
<h4 id="reverse-mode-2"><a class="header" href="#reverse-mode-2">Reverse Mode</a></h4>
<p>Both the in-place and "normal" variant return the gradient. The difference is that with <code>Active</code> the gradient is returned and with <code>Duplicated</code> the gradient is accumulated in-place.</p>
<h3 id="usage-story"><a class="header" href="#usage-story">Usage story</a></h3>
<p>Let us start by looking at the most basic examples we can think of:</p>
<p>\[ f(x,y) = x^2 + 3y \]</p>
<p>We have two input variables \(x\), \(y\) and a scalar return value.
The gradient is</p>
<p>\[ \nabla f = \Big[\frac{\partial f}{\partial x}, \frac{\partial f}{\partial y} \Big] = \big[2x, 3 \big] \]</p>
<p>Let's check for Enzyme (our compiler explorer does not handle Rust yet, so you'll have to trust me on this).</p>
<pre><code class="language-rust noplayground">    use std::autodiff::autodiff;
    #[autodiff(df, Reverse, Active, Active, Active)]
    fn f(x: f32, y: f32) -&gt; f32 {
        x * x + 3.0 * y
    }

    fn main() {
        let (x, y) = (5.0, 7.0);
        let (z, bx, by) = df(x, y, 1.0);
        assert_eq!(46.0, z);
        assert_eq!(10.0, bx);
        assert_eq!(3.0, by);
    }</code></pre>
<p>Enzyme actually generates the code on LLVM-IR level, but Rust is nicer to read, so I will pretend we would generate a Rust implementation:</p>
<pre><code class="language-rust ignore">fn f(x: f32, y: f32) -&gt; f32 {
  x * x + 3.0 * y
}
fn df(x: f32, y: f32) -&gt; (f32, f32, f32) {
  let d_dx = 2.0 * x;
  let d_dy = 3.0;
  let f = x * x + 3.0 * y;
  (d_dx, d_dy, f)
}</code></pre>
<p>Note that the last entry in the result tuple contains the original return value. However, we don't always pass things by value, so let's make sure we have a sensible solution:</p>
<pre><code class="language-rust ignore">#[autodiff(df, Reverse, Active, Duplicated, Active)]
fn f(x: f32, y: &amp;f32) -&gt; f32 {
  x * x + 3.0 * y
}</code></pre>
<p>(pay attention to <code>y</code>).</p>
<pre><code class="language-rust ignore">fn f(x: f32, y: f32) -&gt; f32 {
  x * x + 3.0 * y
}
fn df(x: f32, y: &amp;f32, d_dy: &amp;mut f32) -&gt; (f32, f32) {
  let d_dx = 2.0 * x;
  *d_dy += 3.0;
  let f = x * x + 3.0 * y
  (d_dx, f)
}</code></pre>
<p>In the case of references (or pointers) we do expect the user to create <code>d_dy</code>.</p>
<p>We could obviously zero-initialize a float for the user, but let's assume the constructor is complex due to involving a double-linked-list or ffi, so we can't guarantee that on the compiler side. As an alternative motivation, imagine that we call <code>df</code> 5 times in a loop. It is clear that in this case the accumulated gradients should be 5 times higher too, which won't happen if we set <code>d_dy = 3.0</code> each time, instead of using <code>+=</code>. Yet another reason would be higher-order derivatives (todo: just refer to literature?).</p>
<p>Now that we got back from this rabbit hole, let's go wild and train a neural network on our local national lab server:</p>
<pre><code class="language-rust ignore">#[autodiff(backprop, Reverse, Duplicated, Duplicated, Active)]
fn training_loss(images: &amp;[f32], weights: &amp;[f32]) -&gt; f32 {
  let loss = do_some_math(images, weights);
  loss
}</code></pre>
<p>Now Enzyme gives us:</p>
<pre><code class="language-rust ignore">fn training_loss(images: &amp;[f32], weights: &amp;[f32]) -&gt; f32 {
  let loss = do_some_math(images, weights);
  loss
}
fn backprop(images: &amp;[f32], dimages: &amp;mut [f32], weights: &amp;[f32], dweights: &amp;mut [f32]) -&gt; f32 {
  enzyme_update_inplace_dx(dimages);
  enzyme_update_inplace_dy(dweights);
  let loss = do_some_math(images, weights);
  loss
}</code></pre>
<p><em>Uuuuhm. Yeah?</em> We want to minimize our loss, so let's do <code>weights -= learning_rate * dweights;</code></p>
<p>We also just learned how we can update our images through <code>dimages</code>, but unless you know how to shape the world around you that's pretty useless, so we just wasted a good amount of our compute time for not needed gradients. Let's try again:</p>
<pre><code class="language-rust ignore">#[autodiff(backprop, Reverse, Const, Duplicated, Active)]
fn training_loss(images: &amp;[f32], weights: &amp;[f32]) -&gt; f32 {
  let loss = do_some_math(images, weights);
  loss
}</code></pre>
<p>After all, we shouldn't modify our train and test images to improve our accuracy, right? So we now generate:</p>
<pre><code class="language-rust ignore">fn training_loss(images: &amp;[f32], weights: &amp;[f32]) -&gt; f32 {
  let loss = do_some_math(images, weights);
  loss
}
fn backprop(images: &amp;[f32], weights: &amp;[f32], dweights: &amp;mut [f32]) {
  enzyme_update_inplace_dy(dweights);
  let loss = do_some_math(x,y);
  loss
}</code></pre>
<p>Great. No more random dimages that we don't know how to handle. Perfection? Almost:</p>
<pre><code class="language-rust ignore">#[autodiff(backprop, Reverse, Const, Duplicated, DuplicatedNoNeed)]
fn training_loss(images: &amp;[f32], weights: &amp;[f32]) -&gt; f32 {
  let loss = do_some_math(images, weights);
  loss
}</code></pre>
<p>Happy to accept better names than <code>DuplicatedNoNeed</code>. Either way, now we have:</p>
<pre><code class="language-rust ignore">fn training_loss(images: &amp;[f32], weights: &amp;[f32]) -&gt; f32 {
  let loss = do_some_math(images, weights);
  loss
}
fn backprop(images: &amp;[f32], weights: &amp;[f32], dweights: &amp;mut [f32]) {
  enzyme_update_inplace_dy(dweights);
}</code></pre>
<p>We run backprop to get the gradients to update our weights, tracking of the loss while training is optional. Keep in mind that this will allow Enzyme to do some slightly advanced dead code elimination, but at the end of the day Enzyme will still need to compute most of <code>do_some_math(x, y)</code> in order to calculate <code>dy</code>. So how much runtime you save by not asking for loss will depend on your application. We won't introduce a new motivation for our last example, but let's assume we have reasons to only want <code>dweights</code>, but do not care about the original weights anymore.</p>
<pre><code class="language-rust ignore">#[autodiff(backprop, Reverse, Const, DuplicatedNoNeed, DuplicatedNoNeed)]
fn training_loss(images: &amp;[f32], weights: &amp;[f32]) -&gt; f32 {
  let loss = do_some_math(images, weights);
  loss
}</code></pre>
<p><code>DuplicatedNoNeed</code> allows Enzyme to reuse the memory of our <code>weights</code> variable as a scratchspace. That means it might increase the performance, but in exchange the variable shall not be assumed to have meaningful values afterwards. That's obviously only valid in Julia, C++, etc., but not in Rust. We had some discussion on whether this can be represented as MaybeUninit or Option but didn't got to a conclusion yet. (WIP)</p>
<pre><code class="language-rust ignore">fn training_loss(images: &amp;[f32], weights: &amp;[f32]) -&gt; f32 {
  let loss = do_some_math(images, weights);
  loss
}
fn backprop(images: &amp;[f32], weights: &amp;[f32], dweights: &amp;mut [f32]) {
  enzyme_update_inplace_dy(dweights);
}</code></pre>
<p>And as the very last one, Enzyme follows Jax and all the other AD tools by allowing batched backpropagation:</p>
<pre><code class="language-rust ignore">#[autodiff(backprop, Reverse(2), Const, Duplicated, DuplicatedNoNeed)]
fn training_loss(images: &amp;[f32], weights: &amp;[f32]) -&gt; f32 {
  let loss = do_some_math(images, weights);
  loss
}</code></pre>
<p>We don't expose batchmode on the Rust side yet, let's do one step after the other.</p>
<pre><code class="language-rust ignore">fn training_loss(images: &amp;[f32], weights: &amp;[f32]) -&gt; f32 {
  let loss = do_some_math(images, weights);
  loss
}
fn backprop(images: (&amp;[f32], &amp;[f32]), weights: (&amp;[f32], &amp;[f32]), dweights: (&amp;mut f[f32], &amp;mut [f32])) {
  enzyme_update_inplace_dy(dweights.0);
  enzyme_update_inplace_dy(dweights.1);
}</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="higher-order-derivatives"><a class="header" href="#higher-order-derivatives">Higher Order Derivatives</a></h1>
<p>Computing higher order derivatives like hessians can be done with std::autodiff by differentiating functions that compute lower order derivatives.</p>
<pre><pre class="playground"><code class="language-rust">// A direct translation of
// https://enzyme.mit.edu/index.fcgi/julia/stable/generated/autodiff/#Forward-over-reverse

#[autodiff(ddf, Forward, Dual, Dual, Dual, Dual)]
fn df2(x: &amp;[f32;2], dx: &amp;mut [f32;2], out: &amp;mut [f32;1], dout: &amp;mut [f32;1]) {
    df(x, dx, out, dout);
}

#[autodiff(df, Reverse, Duplicated, Duplicated)]
fn f(x: &amp;[f32;2], y: &amp;mut [f32;1]) {
    y[0] = x[0] * x[0] + x[1] * x[0]
}

#[test]
fn main() {
    let mut y = [0.0];
    let x = [2.0, 2.0];

    let mut dy = [0.0];
    let mut dx = [1.0, 0.0];

    let mut bx = [0.0, 0.0];
    let mut by = [1.0];
    let mut dbx = [0.0, 0.0];
    let mut dby = [0.0];

    ddf(&amp;x, &amp;mut bx, &amp;mut dx, &amp;mut dbx, 
        &amp;mut y, &amp;mut by, &amp;mut dy, &amp;mut dby);
}</code></pre></pre>
<div style="break-before: page; page-break-before: always;"></div><h3 id="python-integration"><a class="header" href="#python-integration">Python Integration</a></h3>
<p>std::autodiff is fully handled by the Rust compiler and therefore should not cause any issues with Python integration.
An example for maturin/PyO3 is provided below. You will still need to enable <code>lto=fat</code> in your Cargo.toml and adjust
the module name to match your project, otherwise python won't be able to find your functions.
The first <code>#[pyfunction]</code> macro will only be applied to the original function <code>f</code>.
We therefore add a small wrapper function <code>df_py</code> and apply the <code>#[pyfunction]</code> macro to it.</p>
<pre><code class="language-toml">
```rs 
#![feature(autodiff)]
use std::autodiff::autodiff;
use pyo3::prelude::*;

#[pyfunction]
#[autodiff(df, Reverse, Active, Active)]
fn f(x: f32) -&gt; f32 {
    x * x
}

// Will return x*x and 2*x
#[pyfunction]
fn df_py(x: f32) -&gt; (f32, f32) {
    df(x, 1.0)
}

// Remember to adjust the name of the module to match your project
#[pymodule]
fn my_module(m: &amp;Bound&lt;'_, PyModule&gt;) -&gt; PyResult&lt;()&gt; {
    m.add_function(wrap_pyfunction!(f_py, m)?)?;
    m.add_function(wrap_pyfunction!(df_py, m)?)?;
    Ok(())
}
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="current-limitations"><a class="header" href="#current-limitations">Current limitations</a></h1>
<p><a href="https://rustc-dev-guide.rust-lang.org/autodiff/limitations.html">Current limitations</a> are tracked in the rustc-dev-guide.</p>
<h1 id="future-work"><a class="header" href="#future-work">Future Work</a></h1>
<h3 id="parallelism"><a class="header" href="#parallelism">Parallelism:</a></h3>
<p>Enzyme supports the ability to efficiently differentiate parallel code. Enzyme's unique ability to combine optimization (including parallel optimization) enables orders of magnitude improvements on performance and <a href="https://ieeexplore.ieee.org/document/10046093">scaling parallel code</a>. Each parallel framework needs only provide Enzyme lightweight markers describing where the parallelism is created (e.g. this is a parallel for or spawn/sync). Such markers have been added for various parallel paradigms, including: CUDA, ROCm, OpenMP, MPI, Julia tasks, and RAJA.</p>
<p>Such markers have not been added for Rust parallel libraries (i.e. rayon). Enzyme only does need to support the lowest level of parallelism for each language,
so adding support for rayon should cover most cases. We assume 20-200 lines of code in
Enzyme core should be sufficient, making it a nice task to get started.<br />
<a href="https://github.com/rsmpi/rsmpi">rsmpi</a> (Rust wrapper for MPI) should already work, but it would be good to test.</p>
<h3 id="custom-derivatives"><a class="header" href="#custom-derivatives">Custom Derivatives</a></h3>
<p>Let's assume that you want to use <a href="https://arxiv.org/abs/2006.12057">differentiable rendering</a>,
but someone added a "fast" version of the <a href="https://en.wikipedia.org/wiki/Fast_inverse_square_root#Overview_of_the_code">inverse square root function</a> to your render engine,
breaking your Rust-Enzyme tool, which can't figure out how <code>i  = 0x5f3759df - ( i &gt;&gt; 1 );</code> would affect your gradient.
AutoDiff packages for this reason allow declaring a custom derivative <code>f'</code> for a function <code>f</code>.
In such a case the AD tool will not look at the implementation of <code>f</code> and directly use the user provided <code>f'</code>.
Jax documentation also has a large list of other reasons due to which you might want to use custom derivatives: <a href="https://jax.readthedocs.io/en/latest/notebooks/Custom_derivative_rules_for_Python_code.html">link</a>.
Julia has a whole ecosystem called <a href="https://juliadiff.org/ChainRulesCore.jl/stable/">ChainRules.jl</a> around custom derivatives.
Enzyme does support custom derivatives, but we do not expose this feature on the Rust side yet.
Together with the Batching features, this is one of the highest rewards / lowest effort improvements planed for Rust-Enzyme.</p>
<h3 id="custom-allocators"><a class="header" href="#custom-allocators">Custom Allocators:</a></h3>
<p>Enzyme does support custom allocators, but Rust-Enzyme does not expose support for it yet.
Please let us know if you have an application that can benefit from a custom allocator and autodiff,
otherwise this likely won't be implemented in the forseeable future.</p>
<h3 id="checkpointing"><a class="header" href="#checkpointing">Checkpointing:</a></h3>
<p>While Enzyme is very fast due to running optimizations before AD, including various partial checkpointing algorithms -- such as a <a href="https://dl.acm.org/doi/abs/10.1145/3458817.3476165">min-cut algorithm</a>. The ability to control checkpointing (e.g. whether to recompute or store) has not yet been added to Rust. Optimal checkpointing generally lies in NP to find the optimal balance for each given program, but there are good approximations. You can think of it in terms of custom allocators. Replacing the algorithm might affect your runtime performance, but does not affect the result of your function calls. In the future it might be interesting to let the user interact with checkpointing.</p>
<h3 id="supporting-other-codegen-backends"><a class="header" href="#supporting-other-codegen-backends">Supporting other Codegen backends:</a></h3>
<p>Enzyme consists of ~50k LoC. Most of the rules around generating derivatives for instructions are written in LLVM Tablegen.td declarations and as such it should be relatively easy to port them. Enzyme also includes various experimental features which we don't need on the Rust side, an implementation for another codegen backend could therefore also end up a bit smaller.
The cranelift backend would also benefit from ABI compatibility, which makes it very easy to test correctness of a new autodiff tool against Enzyme. Our modifications to <code>rustc_codegen_ssa</code> and previous layers of rustc are written in a generic way, s.t. no changes would be needed there to enable support for additional backends.</p>
<h3 id="gpu--tpu--ipu---support"><a class="header" href="#gpu--tpu--ipu---support">GPU / TPU / IPU / ... support.</a></h3>
<p>Enzyme supports differentiating CUDA/ROCm Kernels.
There are various ways towards exposing this capabilities to Rust.
Manuel and Jed will be experimenting with two different approaches in 2024,
and there is also a lot of simultaneous research. Please reach out if
you are also working on GPU programming in Rust.</p>
<h3 id="mlir-support"><a class="header" href="#mlir-support">MLIR support:</a></h3>
<p>Enzyme partly supports multiple MLIR dialects. MLIR can offer great runtime
performance benefits for certain workloads. It would be nice to have a
<code>rustc_codegen_mlir</code>, but there is a very large number of open questions around the design.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="history-and-ecosystem"><a class="header" href="#history-and-ecosystem">History and ecosystem</a></h1>
<p>Enzyme started as a project created by William Moses and Valentin Churavy to differentiate the LLVM-IR, including languages with an LLVM frontends like C, Julia, Swift, Fortran, etc. Operating within the compiler enables Enzyme to interoperate with optimizations, allowing for higher performance than conventional methods while simultaneously not needing special handling for each language and construct. Enzyme is an LLVM Incubator projects and intends to ask for upstreaming later in 2024.</p>
<p>In 2020, initial investigations on using Enzyme on Rust was led by Tiberius Ferreria and William Moses through the use of foreign function calls (https://internals.rust-lang.org/t/automatic-differentiation-differential-programming-via-llvm/13188/7).</p>
<p>In 2021, Manuel Drehwald and Lorenz Schmidt worked on <a href="https://github.com/EnzymeAD/oxide-enzyme">Oxide-Enzyme</a> which aimed to directly integrate Enzyme as a compiler-aware cargo plugin.</p>
<p>The current <a href="https://github.com/EnzymeAD/rust">Rust-Enzyme</a> project direct embeds Enzyme into rust and makes available autodiff macros for easy usage. The project is led by Manuel Drehwald, in collaboration with Jed Brown, William Moses, Lorenz Schmidt, Ningning Xie, and Rodrigo Vargas-Hernandez.</p>
<h2 id="development-of-a-rust-enzyme-frontend"><a class="header" href="#development-of-a-rust-enzyme-frontend">Development of a Rust-Enzyme frontend</a></h2>
<p>We hope that as part of the nightly releases Rust-Enzyme can mature relatively fast because:</p>
<ol>
<li>Unlike Julia, Rust does not emit code involving Garbage Collection, JIT, or Type Unstable code -- simplifying the inputs to Enzyme (and reducing the need to develop support for such mechanisms, which have since been added to Enzyme.jl).</li>
<li>Unlike Clang, we do ship the source code for the standard library. On the Rust side, we therefore don't need to manually add support for functions libstdc++ like <a href="https://github.com/EnzymeAD/Enzyme/pull/764/files#diff-33703e707eb3c80e460e135bec72264fd2380201070a2959c6755bb26c72a504R190"><code>std::map decrement</code></a>.</li>
<li>Minimizing Rust code is reasonably nice and Cargo/crates.io makes it easy to reproduce bugs.</li>
</ol>
<h2 id="non-alternatives"><a class="header" href="#non-alternatives">Non-alternatives</a></h2>
<p>The key aspect for the performance of our solution is that AD is performed after compiler optimizations have been applied
(and is able to run additional optimizations). This observation is mostly language independent and motivated in the
<a href="https://proceedings.neurips.cc/paper/2020/file/9332c513ef44b682e9347822c2e457ac-Paper.pdf">2020 Enzyme Neurips paper</a>, and also mentioned towards the end of this non-Enzyme java autodiff <a href="https://github.com/openjdk/babylon-docs/blob/master/site/articles/auto-diff.md">case-study</a>.</p>
<h3 id="wrapping-cargo-instead-of-modifying-rustc"><a class="header" href="#wrapping-cargo-instead-of-modifying-rustc">Wrapping cargo instead of modifying rustc</a></h3>
<p>We can use Enzyme without modifying rustc, as demonstrated in <a href="https://github.com/enzymeAD/oxide-enzyme">oxide-enzyme</a>.</p>
<ol start="0">
<li>We let users specify a list of functions which they want to differentiate and how (forward/reverse, activities...). <a href="https://github.com/EnzymeAD/oxide-enzyme/blob/main/example/rev/build.rs">example</a>.</li>
<li>We manually emit the optimized llvm-ir of our rust programs and all dependencies.</li>
<li>We llvm-link all files into a single module (equivalent to fat-lto).</li>
<li>We call Enzyme to differentiate functions.</li>
<li>We adjust linker visibility of the new functions and create an archive that exports those new functions.</li>
<li>We terminate this cargo invocation (can e.g. be achieved by -Zno-link).</li>
<li>We call cargo a second time, this time providing our archive as additional linker argument. The functions provided by the archive exactly match the extern fn declarations created through our macro <a href="https://github.com/EnzymeAD/oxide-enzyme/blob/main/example/rev/src/main.rs">here</a>.</li>
</ol>
<p>This PoC required the use of <code>build-std</code>, to be able to see the llvm-ir of functions from the std lib.<br />
An alternative would have been to provide rules for Enzyme on how to differentiate every function from the Rust std, which seems undesirable. It would however not be impossible, C++-Enzyme has various rules for the C++ std lib.</p>
<p>This approach also assumes that linking llvm-ir generated by two different cargo invocations and passing Rust objects between those works fine.</p>
<p>This approach is further limited in compile times and reliability. See the example at the bottom left of this <a href="https://c.wsmoses.com/posters/Enzyme-llvmdev.pdf">poster</a>. LLVM types are often too limited to determine the correct derivative (e.g. opaque ptr),
and as such Enzyme has to run a usage analysis to determine the relevant type of a variable. This can be time consuming
(we encountered multiple cases with &gt; 1000x longer compile times) and it can be unreliable, if Enzyme fails to deduce the correct type
of a variable due to insufficient usages. When calling Enzyme from within rustc, we are able to provide high-level type information to Enzyme.
For oxide-enzyme, we tried to mitigate this by using a Dwarf debug parser (requiring debug information even in release builds), but even with this helpers we were completely unable to support Enums due to their ability of representing different types. This approach was also limited since rustc (at the time we wrote it) did not emit Dwarf information for all Rust types with unstable layout.</p>
<h3 id="rust-level-autodiff"><a class="header" href="#rust-level-autodiff">Rust level autodiff</a></h3>
<p>Various Rust libraries for the training of Neural Networks exist (burn/candle/dfdx/rai/autograph).
We talked with developers from burn, rai, and autograph to compare the autodiff performance under the Microsoft <a href="https://github.com/microsoft/ADBench/">ADBench</a> Benchmark suite. After some investigation all three decided that supporting such cases would require significant redesigns of their projects, which they can't afford in the forseeable future.<br />
When training Neural Networks, we often look at few large variables (tensors) and a small set of functions (layers) which dominate the runtime. Using these properties it's possible to amortize some inefficiencies by getting the most expensive operations efficient. Such optimizations stop working, once we look at the larger set of applications for scientific computing or HPC.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="how-to-debug-ad"><a class="header" href="#how-to-debug-ad">How to Debug AD?</a></h1>
<p><a href="https://rustc-dev-guide.rust-lang.org/autodiff/debugging.html">Debug instructions</a>, and more information about the <a href="https://rustc-dev-guide.rust-lang.org/autodiff/flags.html">autodiff flag</a> is available in the rustc-dev-guide.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="other-enzyme-frontends"><a class="header" href="#other-enzyme-frontends">Other Enzyme frontends</a></h1>
<p>Enzyme currently has experimental frontends for C/C++, Julia, Fortran, Numba, some MLIR dialects, and Rust.</p>
<p>General LLVM/MLIR, as well as C/C++/CUDA documentation is available at <a href="https://enzyme.mit.edu">https://enzyme.mit.edu</a><br />
Julia documentation is available at <a href="https://enzyme.mit.edu/julia">https://enzyme.mit.edu/julia</a><br />
Rust  documentation is available at <a href="https://enzyme.mit.edu/rust">https://enzyme.mit.edu/rust</a><br />
Enzyme-JAX (including HLO MLIR AD) is available at <a href="https://github.com/EnzymeAD/Enzyme-JAX">https://github.com/EnzymeAD/Enzyme-JAX</a>.
Enzyme has been demonstrated on various other languages including <a href="https://passivelogic.com/blog/?post=using-enzyme-autodiff-with-swift&amp;category=autodiff">Swift</a>, and <a href="https://github.com/ludgerpaehler/LULESH-Fortran/blob/main/Makefile">Fortran</a>, but no frontend has been developed to improve ease of use and installation for these languages.</p>
<p>We have a compiler-explorer fork with support for autodiff in C/C++/CUDA, Julia, and MLIR <a href="https://enzyme.mit.edu/explorer">here</a>.</p>
<p>Developer documentation is available at <a href="https://enzyme.mit.edu/doxygen">https://enzyme.mit.edu/doxygen</a><br />
Please reach out if you would like to see support for additional languages.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="forward-mode-2"><a class="header" href="#forward-mode-2">Forward Mode</a></h1>
<p>When using forward mode, we only have three choices of activity values, <code>Dual</code>, <code>DualOnly</code> and <code>Const</code>.
Dual arguments get a second "shadow" variable.
Usually we will only seed the shadow variable of one Dual input to one and all others to zero,
and then read the shadow values of our output arguments.
We can also seed more then one input shadow, in which case the shadow of output variables will
be a linear combination based on the seed values.
If we use a <code>&amp;mut </code> reference as input and output argument and mark it as Dual,
the corresponding shadow seed might get overwritten. Otherwise, the seed value will remain unchanged.</p>
<h1 id=""><a class="header" href="#"></a></h1>
<div class="table-wrapper"><table><thead><tr><th>Activity</th><th>Dual</th><th>DualOnly</th><th>Const</th></tr></thead><tbody>
<tr><td>Non integer input <code>T</code></td><td>Accept <code>T</code>,<code>T</code></td><td>Accept <code>byVal(T)</code>, <code>T</code></td><td>Unchanged</td></tr>
<tr><td>Integer scalar input</td><td>N/A</td><td>N/A</td><td>Unchanged</td></tr>
<tr><td><code>f32</code> or <code>f64</code> output <code>T</code></td><td>Return (T,T)</td><td>Return T</td><td>Unchanged</td></tr>
<tr><td>Other output types</td><td>N/A</td><td>N/A</td><td>Unchanged</td></tr>
</tbody></table>
</div>
<p><code>DualOnly</code> is a potentially faster version of <code>Dual</code>.</p>
<p>When applied to a return type, it will cause the primal return to not be computed.
So in the case of <code>fn f(x: f32) -&gt; f32 { x * x }</code>,
we would now only return <code>2.0 * x</code>, instead of
<code>(x * x, 2.0 * x)</code>, which we would get with <code>Dual</code>.</p>
<p>In the case of an input variable, <code>DualOnly</code> will cause the first value to be
passed by Value, even when passed by Reference in the original function.
So <code>fn f(x: &amp;f32, out: &amp;mut f32) {..}</code> would become
<code>fn df(x: f32, dx &amp;mut f32, out: f32, dout: &amp;mut f32) {..}</code>.<br />
This makes <code>x</code> and <code>out</code> inaccessible for the user, so we can use it as buffer
and potentially skip certain computations. This is mostly valuable for larger Types, or more complex functions.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="reverse-mode-3"><a class="header" href="#reverse-mode-3">Reverse Mode</a></h1>
<p>Reverse Mode reverts the normal control flow, so in this case we will have to seed output variables.
This can be a bit counter-intuitive at first, so we provide an additional helper for float arguments.</p>
<p>When marking a float input as <code>Active</code>, we will internally treat it as having a seed of one. So there will
be no extra input argument. We will then return the resulting float, either directly, or if your primal function
already has a return value, we will update the new function to return a touple, with one additional float per <code>Active</code> input.
Those additional float values are in the same order as your <code>Active</code> input float values.
If you instead want to seed a float output, you can still mark it as <code>Active</code>. We will then append one float argument to
the list of input arguments, which will work as your seed.</p>
<p>More advanced types which are passed by pointer or reference can be marked as <code>Duplicated</code>.
In this case a shadow argument will be added. Please note that unlike forward mode, the
shadow here will always be mutable, therefore <code>*mut</code> or <code>&amp;mut</code>. This is necessary since we have
to overwrite (zero) your seed values for correctness. A motivation for this is given below.</p>
<h1 id="-1"><a class="header" href="#-1"></a></h1>
<div class="table-wrapper"><table><thead><tr><th>Activity</th><th>Active</th><th>Duplicated</th><th>Const</th></tr></thead><tbody>
<tr><td><code>f32</code> or <code>f64</code> Input</td><td>Return additional float</td><td>N/A</td><td>Unchanged</td></tr>
<tr><td><code>&amp;T</code> or <code>&amp;mut T</code> Input</td><td>N/A</td><td>Add <code>&amp;mut T</code> shadow</td><td>Unchanged</td></tr>
<tr><td>Other Input Types</td><td>N/A</td><td>N/A</td><td>Unchanged</td></tr>
<tr><td><code>f32</code> or <code>f64</code> Output</td><td>Append float to inputs</td><td>N/A</td><td>Unchanged</td></tr>
<tr><td>Other Output Types</td><td>N/A</td><td>N/A</td><td>Unchanged</td></tr>
</tbody></table>
</div>
<p>Similar to Forward Mode, we offer optimized versions of our Activity Types.</p>
<h1 id="-2"><a class="header" href="#-2"></a></h1>
<div class="table-wrapper"><table><thead><tr><th>Activity</th><th>ActiveOnly</th><th>DuplicatedOnly</th></tr></thead><tbody>
<tr><td><code>f32</code> or <code>f64</code> Input</td><td>N/A</td><td>N/A</td></tr>
<tr><td><code>&amp;T</code> or <code>&amp;mut T</code> Input</td><td>N/A</td><td>Accept <code>T, &amp;mut T</code></td></tr>
<tr><td><code>f32</code> or <code>f64</code> Output</td><td>Omit primal return value <br> Append float to inputs</td><td>N/A</td></tr>
</tbody></table>
</div>
<p><code>ActiveOnly</code> can not yield any optimization for input values, since it is only
applicable to floats passed by value. When used on a return type, it has the same
effect as <code>DualOnly</code> in Forward Mode.
So in the case of <code>fn f(x: f32) -&gt; f32 { x * x }</code>,
we would now only return <code>2.0 * x</code>, instead of
<code>(x * x, 2.0 * x)</code>, which we would get with <code>Active</code>.</p>
<p><code>DuplicatedOnly</code> has the same effect as <code>DualOnly</code> on input Arguments.
The original input will now be taken by Value, allowing to use it
as a scratch space. If the original Type was a mutable reference, we can
additionally save the computation of any updates to that value.</p>
<blockquote>
<div class="warning">
Unlike Forward Mode, Reverse Mode will always overwrite (zero) your seed!   
If you want to call a function generated through Reverse Mode multiple times, you will have to reset your seed values!
</div>
</blockquote>
<div style="break-before: page; page-break-before: always;"></div><h1 id="design"><a class="header" href="#design">Design:</a></h1>
<p>There are naturally three locations where we could introduce our autodiff macro: on the definition side of f, on the definition side of df, or on the call-site of df.<br />
We only have implemented support for the first two, because this is enough to implement the third one with a normal rust macro. Let us look at some example:</p>
<pre><pre class="playground"><code class="language-rust">#![feature(autodiff)]
#[autodiff(df, Reverse, Active, Active)]
fn fsquare(x: f32) -&gt; f32 {
  x * x
}

fn main() {
  let x = 3.14;
  let res = fsquare(x);
  let (res_, dres) = df(x, 1.0);
  // let dres = autodiff!(f, x);
  assert_eq!(dres, 2.0 * x);
  assert_eq!(res, res_);
}</code></pre></pre>
<p>Some tools always compute all gradients, or rely on Dead-Code-Elimination to remove code that would compute gradients unused by users. In comparison, Enzyme does only generate the code needed to compute your gradients from the beginning (and uses and extends various LLVM passes to do so). Therefore it is crucial that users (can) specify only the minimal set of variables as active. Library authors (e.g. faer, minmax, ...) can not reliably predict which gradients users will need, and offering all would cause a combinatorial explosion. We therefore allow users to differentiate functions specified in a dependency. While not technically required, we do enforce that this function in the dependency is marked as public, to not violate Rusts visibility behavior. We believe for now that this is the best compromise for usability, but would be happy to hear feedback. An example:</p>
<pre><pre class="playground"><code class="language-rust compile_fail"><span class="boring">#![feature(autodiff)]
</span>// ; dependency.rs
fn f(x: f32) -&gt; f32 {
  x * x
}

// ; main.rs
#[autodiff(f, Reverse, Active, Active)]
fn df(x: f32, d_df: f32) -&gt; (f32, f32);

fn main() {
  let x = 3.14;
  let res = f(x);
  let (_, dres) = df(x, 1.0);
  assert_eq!(dres, 2.0 * x);
}</code></pre></pre>
<p>The <code>;</code> is our way of ensuring that users can't provide an implementation to it that would later get overwritten by the autodiff tool. We desugare it into a combination of <code>unimplemented!()</code>, inline-asm (noop), and bench-blackbox, to avoid the method being inlined. We take some additional care of this within the compiler.</p>
<p>Let's look at the configuration now:</p>
<ol>
<li>The first argument of our macro is the name (or path) to the "other" function. That is, if we apply our macro to <code>f</code>, then we would put the name of <code>df</code>, which the macro will then generate. If we put our macro on top of an empty function, then the name should be the one of the function which we want to differentiate.</li>
<li>Forward vs Reverse mode: From a math point of view, this one describes in which order we will expand the chain rule, or rather if we want to calculate the vector-jacobian product, or the jacobian-vector product. It has a very large impact on the performance and the following config parameters will differ slightly based on the mode. No real impact beside of performance. Technically something in between Forward and Reverse would be possible, but has not been explored much by Jax, Enzyme, or others.</li>
<li>Activity of arguments, in the order in which they appear in <code>f</code>. If we use ReverseMode and return a non <code>()</code> value, we specify activity for the return too. We are open to discuss the actual names here:<code>Const</code>, <code>Active</code>, <code>Duplicated</code>, <code>DuplicatedNoNeed</code>.</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="rustc-design"><a class="header" href="#rustc-design">rustc Design:</a></h1>
<p>This chapter is not relevant for an autodiff user, but might still be interesting for those curious to include Enzyme into a new language. It is mostly tailored towards people already working on rustc. I would like to claim it is also there to help reviewers, but realistically I just write things down here because I can't remember what I coded yesterday. This is likely incomplete, so please create PR's to extend it!</p>
<p>The first step was to integrate Enzyme (core) itself. We have added it as a submodule to <code>src/tools/enzyme</code> and updated the bootstrapping accordingly.
We had added our autodiff macro in <code>/library</code>, but this approach had to be abandoned for cross-compilation. The current macro is implemented as a <code>rustc_internal_macro</code>.</p>
<p>We had to alter the compilation pipeline in a few places when autodiff is used.
The obvious one is that we have to prevent our source function from getting completely inlined.</p>
<p><code>compiler/rustc_ast/src/expand/autodiff_attrs.rs</code>
This is a new file, containing the logic to parse our autodiff macro into rustc
builtin <code>rustc_autodiff</code> attributes.
This blocks users from tinkering with our internals,
by having to go through the macro.
It has the nice side-effect, that we can implement an erroring dummy fallback if
we see that the <code>llvm_enzyme</code> config hasn't been set when building rustc.</p>
<p><code>compiler/rustc_codegen_llvm/src/attributes.rs</code>:
In <code>from_fn_attrs</code> we query <code>cx.tcx.autodiff_attrs(instance.def_id());</code>
and if we get an autodiff is active (that is a source or a placeholder).
This is to make sure that neither of the too gets inlined, for that we mark them as <code>InlineAttr::Never</code> and pray for the best.</p>
<p><code>compiler/rustc_codegen_ssa/src/codegen_attrs.rs</code>
We added <code>autodiff_attrs</code>, in which we parse <code>rustc_autodiff</code> attributes applied to Functions, and create <code>AutoDiffAttrs</code> out of it, which we return.</p>
<p><code>compiler/rustc_monomorphize/src/partitioning.rs</code>
In <code>place_mono_items</code> we check if the <code>characteristic_def_id</code> of a function exists, and if yes (and if it has an autodiff attrs) we block it from being inserted into <code>internalization_candidates</code> to prevent inlining.</p>
<p><code>compiler/rustc_monomorphize/src/partitioning.rs</code>
In <code>collect_and_partition_mono_items</code> we update things.</p>
<p><code>compiler/rustc_codegen_ssa/src/back/write.rs</code>
In <code>generate_lto_work</code> we pass the autodiff worklist to our backend autodiff function doing the actual work. We check there that our autodiff worklist is empty if we don't use fat-lto.</p>
<p><code>compiler/rustc_middle/src/ty/mod.rs</code>
How to create a typetree or fnctree from a <code>rustc_middle::ty</code></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="unsafe-interface"><a class="header" href="#unsafe-interface">Unsafe Interface</a></h1>
<p>Especially Reverse Mode AD has various code transformations which can easily
cause UB, when not used correctly. We work on catching all cases through our
design and additional safety checks, but are aware that for some cases like
hot loops, or GPU Kernels such checks are not desired.</p>
<p>A motivational (C++) example is given <a href="https://enzyme.mit.edu/getting_started/CallingConvention/#result-only-duplicated-argument">here</a>
This example would be instant UB in Rust because Types must never be in an invalid
state, which is not the case for loss here.
In our safe interface we solve this by accepting Types by value, making the invalid state inaccessible from Rust code. This however requires allocating a new variable for each call, which could become a performance limitation.</p>
<p>While not implemented yet, we propose a second interface, with the bikeshedding
name <code>unsafe_ad</code> instead of <code>autodiff</code>. It will <code>not</code> generate the safety checks
which we discussed in previous sections. The generated Interface also differs for
<code>DualOnly</code> and <code>DuplicatedOnly</code>. See this examples:</p>
<pre><pre class="playground"><code class="language-rust">fn f(x: &amp;[f32], y: &amp;mut f32) {
    y = x[0] * x[0] + x[1] * x[0];
}

#[autodiff(df, Forward, Dual, Dual)]
fn f(x: &amp;[f32], y: &amp;mut f32) { ... }
// fn df(x: &amp;[f32], dx: &amp;mut [f32], y: &amp;mut f32, dy: &amp;mut f32);

fn main() {
    let x  = [2.0, 2.0];
    let dx = [1.0, 0.0];
    let y  = 0.0
    let dy = 0.0;
    df(&amp;x, &amp;mut dx, &amp;mut y, &amp;mut dy);
}</code></pre></pre>
<p>The first optimization here is using <code>DualOnly</code>. Now</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[autodiff(df, Forward, DualOnly, DualOnly)]
fn f(x: &amp;[f32], y: &amp;mut f32) { ... }
// fn df(x: Vec&lt;f32&gt;, dx: &amp;mut[f32], y: f32, dy: &amp;mut f32);
<span class="boring">}</span></code></pre></pre>
<p>Both x and y become inaccessible, so no harm can happen. But let us assume
that we have to reuse these expensive memory allocations.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[unsafe_ad(df, Forward, DualOnly, DualOnly)]
fn f(x: &amp;[f32], y: &amp;mut f32) { ... }
// unsafe fn df(x: MaybeUninit&lt;&amp;[f32]&gt;, dx: &amp;mut[f32], y: MaybeUninit&lt;&amp;mut f32&gt;, dy: &amp;mut f32);
<span class="boring">}</span></code></pre></pre>
<p>We expect both x and y to be in a valid state, however they will be in an invalid state after calling df. This allows us to omit computing their original output value and it also allows us to re-use it's memory location as buffer memory.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="acknowledgments"><a class="header" href="#acknowledgments">Acknowledgments</a></h1>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr.min.js"></script>
        <script src="mark.min.js"></script>
        <script src="searcher.js"></script>

        <script src="clipboard.min.js"></script>
        <script src="highlight.js"></script>
        <script src="book.js"></script>

        <!-- Custom JS scripts -->

        <script>
        window.addEventListener('load', function() {
            MathJax.Hub.Register.StartupHook('End', function() {
                window.setTimeout(window.print, 100);
            });
        });
        </script>

    </div>
    </body>
</html>
